# ContrastTransferLabs
In this repo, I demonstrate supervised contrastive learning in Computer Vision (CV), transfer learning in Natural Language Processing (NLP), and zero-shot transfer learning (also in CV) with the CLIP (Contrastive Language & Image Pre-training) model, commonly used to perform text-to-image generation.

## Part 1: Supervised Contrastive Learning
Supervised Learning is a machine learning tenet that uses labeled data (x->y) to train a model to make inferences. Contrastive Learning on the other hand, can utilize both labeled and non-labeled data. However, incorporating labels into the data while applying contrastive learning can enhance the models' performance.

In this section, supervised contrastive learning is applied on a CV classification task, and compared to a model that does not.


## Part 2: Transfer Learning in NLP

There are three big benefits to transfer learning in the field of machine learning and artificial intelligence: efficiency, performance, and flexibility. It is efficient because it allows the knowledge from a pre-trained model to be transferred onto a new, different model. It also can drastically improve performance on a new task as it incorporates more data, and is flexible as it can be applied on a variety of tasks and models.

In this section, transfer learning is applied onto a natural language processing question-answering task.


## Part 3: Zeroshot Transfer Learning on CV
 Transfer learning is demonstrated using the zeroshot technique - which seeks to improve model performance by generalizing its' knowledge on variations of unstructured and non-labeled data that was not given to the model during training. 

 In this section, zeroshot transfer learning is applied onto a CV classification task with the CLIP model.

# References

[Supervised Contrastive Learning, Google Slides](https://docs.google.com/presentation/d/1UxtHDwjViC7VpSb0zB-kajGQ-TwznQmc-7LsbHRfO3s/edit#slide=id.gcdc5f16e5b_20_5)

[Supervised Contrastive Learning, Towards Data Science Blog](https://towardsdatascience.com/contrastive-loss-for-supervised-classification-224ae35692e7)

[Supervised Contrastive Learning, Keras Documentation](https://keras.io/examples/vision/supervised-contrastive-learning/)

[Transfer Learning in NLP, Tensorflow Documentation](https://www.tensorflow.org/hub/tutorials/tf2_text_classification)

[Transfer Learning in NLP on Tensorflow, Amitness Blog](https://amitness.com/2020/02/tensorflow-hub-for-transfer-learning/)

[Transfer Learning with BiT, Keras Documentation](https://keras.io/examples/vision/bit/)

[Zeroshot Transfer Learning on CV, Towards Data Science Blog](https://towardsdatascience.com/how-to-try-clip-openais-zero-shot-image-classifier-439d75a34d6b)

[Zeroshot Transfer Learning, Tensorflow Documentation](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)

