# ContrastTransferLabs
In this repo, I demonstrate supervised contrastive learning in Computer Vision (CV), transfer learning in Natural Language Processing (NLP), and zero-shot transfer learning (also in CV) with the CLIP (Contrastive Language & Image Pre-training) model, commonly used to perform text-to-image generation.

## Part 1: Supervised Contrastive Learning
Supervised Learning is a machine learning tenet that uses labeled data (x->y) to train a model to make inferences. Contrastive Learning on the other hand, can utilize both labeled and non-labeled data. However, incorporating labels into the data while applying contrastive learning can enhance the models' performance.

In this section, supervised contrastive learning is applied on a CV classification task, and compared to a model that does not.


## Part 2: Transfer Learning in NLP

There are three big benefits to transfer learning in the field of machine learning and artificial intelligence: efficiency, performance, and flexibility. It is efficient because it allows the knowledge from a pre-trained model to be transferred onto a new, different model. It also can drastically improve performance on a new task as it incorporates more data, and is flexible as it can be applied on a variety of tasks and models.

In this section, transfer learning is applied onto a natural language processing question-answering task.


## Part 3: Zeroshot Transfer Learning on CV
 Transfer learning is demonstrated using the zeroshot technique - which seeks to improve model performance by generalizing its' knowledge on variations of unstructured and non-labeled data that was not given to the model during training. 

 In this section, zeroshot transfer learning is applied onto a CV classification task with the CLIP model.

